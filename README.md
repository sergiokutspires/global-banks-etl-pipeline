# Global Banks ETL Pipeline

An end-to-end ETL (Extract, Transform, Load) pipeline built in Python to collect, process, and store market capitalization data of the world's largest banks.

---

## ğŸ“Š Project Overview

This project performs the following steps:

### 1ï¸âƒ£ Extract
- Scrapes the top 10 largest banks by market capitalization.
- Loads raw data into a Pandas DataFrame.

### 2ï¸âƒ£ Transform
- Cleans the Market Cap column.
- Converts USD values to:
  - GBP
  - EUR
  - INR
- Uses exchange rates provided in `exchange_rate.csv`.

### 3ï¸âƒ£ Load
- Saves processed data into:
  - A CSV file
  - A SQLite database table.
- Executes SQL queries for validation.
- Logs ETL process steps into a log file.

---

## ğŸ›  Technologies Used

- Python
- Pandas
- NumPy
- BeautifulSoup (bs4)
- Requests
- SQLite3
- lxml

---

## ğŸ“‚ Project Structure

```
global-banks-etl-pipeline/
â”‚
â”œâ”€â”€ banks_project.py
â”œâ”€â”€ exchange_rate.csv
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

---

## â–¶ï¸ How to Run

1. Clone the repository:

```bash
git clone https://github.com/sergiokutspires/global-banks-etl-pipeline.git
cd global-banks-etl-pipeline
```

2. Install dependencies:

```bash
pip install -r requirements.txt
```

3. Run the pipeline:

```bash
python banks_project.py
```

---

## ğŸ§  Example SQL Queries Executed

```sql
SELECT * FROM Largest_banks;

SELECT AVG(MC_GBP_Billion) FROM Largest_banks;

SELECT Name FROM Largest_banks LIMIT 5;
```

---

## ğŸ“š Context

This project was developed as part of the IBM Data Engineering Professional Certificate program on Coursera and further refined for portfolio presentation.

---

## ğŸš€ Future Improvements

- Modularize pipeline into separate files (extract.py, transform.py, load.py)
- Add Docker support
- Add data validation checks
- Integrate Airflow for orchestration